---
layout: post
title:  "Deep Learning"
categories: [ML4T]
author_profile: true
sidebar_main: true
---

# Deep Learning: Foundations and Concepts (2023) by Christopher M. Bishop and Hugh. Bishop
## Chapter 1. Introduction to Deep Learning

### Definition    
- Machine Learning: A field of technology where solutions are leanred from data, displacing traditional hand-crafted altorithms.
- Deep Learning: A banch of machine learning based on neural networks, inspired by the human brain, used for general-purpose learning from data.

   
### Neural Networks    
- Neurons: basic processing units in the brain, forming complex networks.
- Artificial Neural Networks: simplified mathematical models capturing the properties of neurons, forming the basis for computational learning.

    
### Polynomial function and linear models    
- Polynomial Function

![Screenshot 2024-06-20 at 9 55 57 PM](https://github.com/melody11sung/melody11sung.github.io/assets/125707768/44102d1f-ba01-4aee-99ce-eaf36036a668)
       
- Linear Models: functions that are linear in the unknown parameters (weights).


### Error function    
- Sum-of-squares error function: measures the misfit between the predicted values and the target values.

![Screenshot 2024-06-20 at 9 57 24 PM](https://github.com/melody11sung/melody11sung.github.io/assets/125707768/3b50a131-02c9-42ad-81e6-d59fba74d8d9)

- the values of the coefficients are determined by minimizing the error function.


### Model Complexity    
- choosing model complexity: selecting the order M of the polynomial to balance fitting the data and avoiding overfitting.


### History of Machine Leearning   
- Early neural networks: inspired by the human brain, the basic processing units called neurons.
- Perceptron: an early model with a step function/ activation function

![Screenshot 2024-06-20 at 10 04 35 PM](https://github.com/melody11sung/melody11sung.github.io/assets/125707768/1d5d27fc-c984-4611-8071-93fd8f066b2d)

- Modern deep learning: neural networks with many layers, capable of learning from large datasets.
- Backpropagation: an efficient algorithm for training multi-layer neural networks by propagating errors backwoard through the network.


